{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import scipy.io\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.morphology as mp\n",
    "from skimage import measure\n",
    "import tensorflow as tf\n",
    "\n",
    "#import sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_base_path = os.path.join(os.pardir, 'data') # works for Herman\n",
    "data_base_path = ('data')\n",
    "data_folder = 'project-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "\n",
    "    train_dir = os.path.join(data_base_path, data_folder +'/images/train/')\n",
    "    dir_train_list = sorted(os.listdir(train_dir))\n",
    "    train = [skimage.io.imread(os.path.join(train_dir, file)) for file in dir_train_list]\n",
    "\n",
    "    \n",
    "    test_dir = os.path.join(data_base_path, data_folder +'/images/test/')\n",
    "    dir_test_list = sorted(os.listdir(test_dir))\n",
    "    test = [skimage.io.imread(os.path.join(test_dir, file)) for file in dir_test_list]\n",
    "    \n",
    "    val_dir = os.path.join(data_base_path, data_folder +'/images/validation/')\n",
    "    dir_val_list = sorted(os.listdir(val_dir))\n",
    "    validation = [skimage.io.imread(os.path.join(val_dir, file)) for file in dir_val_list]\n",
    "    \n",
    "    return train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations():\n",
    "    dir_train = os.path.join(data_base_path, data_folder + '/annotations/train/')\n",
    "    dir_train_list = sorted(os.listdir(dir_train))\n",
    "    train_files = [f for f in dir_train_list if os.path.isfile(os.path.join(dir_train, f))]\n",
    "    train_annotations = [parse_xml_file(os.path.join(dir_train, file)) for file in train_files]\n",
    "    \n",
    "    \n",
    "    dir_test = os.path.join(data_base_path, data_folder + '/annotations/test/')\n",
    "    dir_test_list = sorted(os.listdir(dir_test))\n",
    "    test_files = [f for f in dir_test_list if os.path.isfile(os.path.join(dir_test, f))]\n",
    "    test_annotations = [parse_xml_file(os.path.join(dir_test, file)) for file in test_files]\n",
    "    \n",
    "    dir_val = os.path.join(data_base_path, data_folder + '/annotations/validation/')\n",
    "    dir_val_list = sorted(os.listdir(dir_val))\n",
    "    val_files = [f for f in dir_val_list if os.path.isfile(os.path.join(dir_val, f))]\n",
    "    validation_annotations = [parse_xml_file(os.path.join(dir_val, file)) for file in val_files]\n",
    "    \n",
    "    return train_annotations, test_annotations, validation_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations, test_annotations, validation_annotations = load_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_yellow(img):\n",
    "    out = img.copy()\n",
    "    \n",
    "    red = out[:,:,0]\n",
    "    green = out[:,:,1]\n",
    "    blue = out[:,:,2]\n",
    "    \n",
    "    is_yellow =  (red > 100) & (red < 250) & (green > 100) & (green < 250) & (blue > 0) & (blue < 200)\n",
    "    \n",
    "    red[is_yellow] = 255\n",
    "    green[is_yellow] = 255\n",
    "    blue[is_yellow] = 255\n",
    "    \n",
    "    out[:,:,0] = red\n",
    "    out[:,:,1] = green\n",
    "    out[:,:,2] = blue\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholding the image between two thresholds\n",
    "def threshold(image, th1, th2):\n",
    "    th_img = image.copy()\n",
    "    th_img[th_img<th1] = 0\n",
    "    th_img[th_img>th2] = 0\n",
    "    th_img[(th_img>=th1) & (th_img<=th2)] = 255\n",
    "    return th_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(img, nb):\n",
    "    out = img.copy()\n",
    "    for i in range(nb):\n",
    "        out = mp.erosion(mp.erosion(skimage.img_as_ubyte(img)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef preprocess_image(img):\\n    img = remove_yellow(img)\\n    img_g = rgb2gray(img)\\n    img_th = mp.erosion(mp.erosion(threshold(skimage.img_as_ubyte(img_g), 1, 100)))\\n    return img_th\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    out = img.copy()\n",
    "    out = remove_yellow(out)\n",
    "    img_g = rgb2gray(out)\n",
    "    img_th = threshold(skimage.img_as_ubyte(img_g), 1, 100)\n",
    "    img_er = erode(img_th,1)\n",
    "    return img_er\n",
    "\n",
    "\"\"\"\n",
    "def preprocess_image(img):\n",
    "    img = remove_yellow(img)\n",
    "    img_g = rgb2gray(img)\n",
    "    img_th = mp.erosion(mp.erosion(threshold(skimage.img_as_ubyte(img_g), 1, 100)))\n",
    "    return img_th\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(train, test, validation):\n",
    "    train_out = train.copy()\n",
    "    test_out = test.copy()\n",
    "    val_out = validation.copy()\n",
    "    \n",
    "    for i in range(len(train_out)):\n",
    "        train_out[i] = preprocess_image(train_out[i])\n",
    "        \n",
    "    for i in range(len(test_out)):\n",
    "        test_out[i] = preprocess_image(test_out[i])\n",
    "        \n",
    "    for i in range(len(val_out)):\n",
    "        val_out[i] = preprocess_image(val_out[i])\n",
    "         \n",
    "    return train_out, test_out, val_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ada/lib/python3.6/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "train_pro, test_pro, validation_pro = preprocess_images(train, test, validation[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb train images     : 800\n",
      "Nb test images      : 50\n",
      "Nb validation images: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb train images     : {}\".format(len(train_pro)))\n",
    "print(\"Nb test images      : {}\".format(len(test_pro)))\n",
    "print(\"Nb validation images: {}\".format(len(validation_pro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp, fp, fn):\n",
    "    if (tp == 0):\n",
    "        return 0\n",
    "    return 2 * precision(tp, fp) * recall(tp, fn) / (precision(tp, fp) + recall(tp, fn))\n",
    "\n",
    "def iou_bbox(predict, true):\n",
    "    \"\"\"\n",
    "    Calculate the IoU for two bounding boxes.\n",
    "    Based on:\n",
    "    https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    x_left   = max(predict[0], true[0])\n",
    "    y_bottom = max(predict[1], true[1])\n",
    "    x_right  = min(predict[0] + predict[2], true[0] + true[2])\n",
    "    y_top    = min(predict[1] + predict[3], true[1] + true[3])\n",
    "\n",
    "    # If they do not overlap, return 0\n",
    "    if x_right < x_left or y_bottom > y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_top - y_bottom)\n",
    "\n",
    "    # Compute area for both bounding boxes\n",
    "    bb1_area = predict[2] * predict[3]\n",
    "    bb2_area = true[2] * true[3]\n",
    "\n",
    "    # Compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_method(method, nb_test_images = None, printVals = False):\n",
    "    \n",
    "    def update_progress(progress):\n",
    "        bar_length = 30\n",
    "        if isinstance(progress, int):\n",
    "            progress = float(progress)\n",
    "        if not isinstance(progress, float):\n",
    "            progress = 0\n",
    "        if progress < 0:\n",
    "            progress = 0\n",
    "        if progress >= 1:\n",
    "            progress = 1\n",
    "            \n",
    "        block = int(round(bar_length * progress))\n",
    "        clear_output(wait = True)\n",
    "        text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "        print(text)\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    # setup progress bar\n",
    "    limit = len(test_pro[:nb_test_images] if nb_test_images != None else test_pro)\n",
    "\n",
    "    for i in range(limit):\n",
    "        update_progress(i/limit)\n",
    "        # predict varroas\n",
    "        varroas_pred = method(test_pro[i])\n",
    "\n",
    "        # get true bounding boxes\n",
    "        varroas_true = []\n",
    "        for bbox in test_annotations[i]:\n",
    "               varroas_true.append(bbox['bbox'])\n",
    "\n",
    "        # get true and false positives\n",
    "        positives = []\n",
    "\n",
    "        for pb in varroas_pred:\n",
    "            true_pos = False\n",
    "\n",
    "            for tb in varroas_true:\n",
    "                if(iou_bbox(pb, tb) > 0.3):\n",
    "                    true_pos = True\n",
    "                    break;\n",
    "            positives.append(true_pos)\n",
    "\n",
    "        tp += positives.count(True)\n",
    "        fp += positives.count(False)\n",
    "\n",
    "        # get the false negatives\n",
    "        negatives = []\n",
    "\n",
    "        for tb in varroas_true:\n",
    "            fn = False\n",
    "\n",
    "            for pb in varroas_pred:\n",
    "                if(iou_bbox(pb, tb) > 0.3):\n",
    "                    fn = True\n",
    "                    break;\n",
    "            negatives.append(fn)\n",
    "\n",
    "        # Count all times no intersection was found\n",
    "        fn += negatives.count(False)\n",
    "    update_progress(1)\n",
    "    \n",
    "    if printVals :\n",
    "        print('The values for the given test images')\n",
    "        print(tp)\n",
    "        print(fn)\n",
    "        print(fp)\n",
    "\n",
    "    \n",
    "    print(\"\\n----------- SCORES -----------\")\n",
    "    print(\"Precision: {}\".format(precision(tp,fp)))\n",
    "    print(\"Recall   : {}\".format(recall(tp,fn)))\n",
    "    print(\"F1-score : {}\".format(f1_score(tp,fp,fn)))\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img):\n",
    "    contours = measure.find_contours(img, 0)\n",
    "    lengths = []\n",
    "    for cnt in contours:\n",
    "        lengths.append(len(cnt))\n",
    "    return contours, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_threshold_length(contours, th_low = 0, th_high = np.Inf) :\n",
    "    # filters list of contours, keeps those within threshold limits\n",
    "    out = []\n",
    "    for n, contour in enumerate(contours):\n",
    "        if len(contour) > th_low and len(contour) < th_high :\n",
    "            out.append(contour)\n",
    "    return out, len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours2boxlist(contours):\n",
    "    boxes = []\n",
    "    for contour in contours :\n",
    "        x_min = int(np.min(contour[:,1]))\n",
    "        x_max = int(np.max(contour[:,1]))\n",
    "        y_min = int(np.min(contour[:,0]))\n",
    "        y_max = int(np.max(contour[:,0]))\n",
    "        \n",
    "        boxes.append([x_min, y_min, x_max - x_min, y_max - y_min])\n",
    "    \n",
    "    return boxes # [[x_1, y_1, w_1, h_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    #img = preprocess_image(img)\n",
    "    contours,_ = find_contours(img)\n",
    "    contours,_ = contour_threshold_length(contours,40,80)\n",
    "    boxlist = contours2boxlist(contours)\n",
    "    \n",
    "    return boxlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##############################] 100.0%\n",
      "\n",
      "----------- SCORES -----------\n",
      "Precision: 0.04203670811130847\n",
      "Recall   : 0.9861111111111112\n",
      "F1-score : 0.08063600227143669\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Your code\n",
    "validate_method(detect_by_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create our training features for the classifier. This is done by first finding the contours for all training annotations and then using them to compute the first 10 fourier descriptors of all contours. These will be our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(images, annotations):\n",
    "    '''\n",
    "    Input: Training images and training annotations\n",
    "    Output: Max length of the contours and an array with the contours of all training varroas\n",
    "    '''\n",
    "    max_len = 0\n",
    "    all_contours = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        for anno in annotations[i]:\n",
    "            bbox = anno['bbox']\n",
    "            img_box = images[i][bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]].copy()\n",
    "            im_bw = img_box\n",
    "\n",
    "            # Find contours using opencv\n",
    "            _, contours, _ = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            # Reshape to easily get x and y\n",
    "            if (len(contours) != 0):\n",
    "                contours_np = contours[0][:, 0, :]\n",
    "                all_contours.append(contours_np)\n",
    "\n",
    "                if (max_len < contours_np.shape[0]):\n",
    "                    max_len = contours_np.shape[0]\n",
    "\n",
    "    return max_len, np.array(all_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_descriptor(contours, length):\n",
    "    '''\n",
    "    Input: one contour, max lenght of all contours\n",
    "    Output: The 10 first fourrier descriptors of the contour\n",
    "    '''\n",
    "    \n",
    "    # Pad contour to max contour length\n",
    "    for i in range(length - len(contours)):\n",
    "        contours = np.concatenate([contours, np.array([[0, 0]])])\n",
    "    \n",
    "    # Create imag nums and descriptors\n",
    "    u_k = contours[:, 0] + 1j*contours[:, 1]\n",
    "    \n",
    "    fr = np.fft.fft(u_k)\n",
    "    \n",
    "    # Only return the 2nd and 3rd\n",
    "    return [fr[1], fr[2], fr[3], fr[4], fr[5], fr[6], fr[7], fr[8], fr[9], fr[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and normalize training features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len, contours = get_contours(train_pro, train_annotations)\n",
    "features = np.abs([(fourier_descriptor(c, max_len)) for c in contours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.c_[ features, np.zeros(features.shape[0]) ]  \n",
    "scaler = preprocessing.StandardScaler().fit(features[:, 0:10])\n",
    "features_s = scaler.transform(features[:, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto_deprecated',\n",
       "      kernel='rbf', max_iter=-1, nu=0.95, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm_one = svm.OneClassSVM(nu=0.95)\n",
    "clf_svm_one.fit(features_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not miss any varroas the sliding window will take quite small steps (6-8px). This means that one varroa might be found several times. A merge_box function is implemented to merge overlapping bounding boxes before returning them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(bboxes_in):\n",
    "    bboxes = bboxes_in.copy()\n",
    "    for i in range(len(bboxes)):\n",
    "        for j in range(i+1, len(bboxes)):\n",
    "            if(iou_bbox(bboxes[i], bboxes[j]) > 0.3):\n",
    "\n",
    "                # Determine the coordinates of the intersection rectangle\n",
    "                x_left = min(bboxes[i][0], bboxes[j][0])\n",
    "                y_top = min(bboxes[i][1], bboxes[j][1])\n",
    "                x_right = max(bboxes[i][0] + bboxes[i][2], bboxes[j][0] + bboxes[j][2])\n",
    "                y_bottom = max(bboxes[i][1] + bboxes[i][3], bboxes[j][1] + bboxes[j][3])\n",
    "                \n",
    "                bboxes[j] = [x_left, y_top, x_right - x_left, y_bottom - y_top]\n",
    "                del bboxes[i]\n",
    "                break\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(image):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    \n",
    "    window_shape = (45, 45)\n",
    "    padding = max_len\n",
    "    varroas = []\n",
    "    for window in sliding_window(image, 6, window_shape):\n",
    "        im_bw = window[2]\n",
    "\n",
    "        # Find contours using opencv\n",
    "        _, contours, _ = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        #print(len(contours))\n",
    "\n",
    "        # Reshape to easily get x and y\n",
    "        if (len(contours) > 0):\n",
    "            contours_np = contours[0][:, 0, :]\n",
    "            descriptor = np.abs(fourier_descriptor(contours_np, padding))\n",
    "            test_ = scaler.transform(np.array([descriptor[:]]))\n",
    "            prob = clf_svm_one.predict(test_.reshape(1, -1))\n",
    "            # print(prob)\n",
    "            if (prob > 0):\n",
    "                varroas.append([window[0], window[1], window_shape[0], window_shape[1]])\n",
    "\n",
    "    return merge_boxes(varroas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation of result by repporting the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##############################] 100.0%\n",
      "\n",
      "----------- SCORES -----------\n",
      "Precision: 0.09669211195928754\n",
      "Recall   : 0.9047619047619048\n",
      "F1-score : 0.17471264367816094\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "validate_method(detect_by_method_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our high recall but really low precision score, we can conclude that we catch most varroas, but also a lot of objects which are not varroas. Improved preprocessing for the images might have helped us elevate the precision, but we think deep learning will be the best solution to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_varroa_images(images, annotations, width, height):\n",
    "    '''\n",
    "    Input: Training images and training annotations\n",
    "    Output: An array with all varroa images\n",
    "    '''\n",
    "    varroas = []\n",
    "    for i in range(len(images)):\n",
    "        for anno in annotations[i]:\n",
    "            bbox = anno['bbox']\n",
    "            img_box = images[i][bbox[1]:bbox[1]+height, bbox[0]:bbox[0]+width].copy()\n",
    "            if (img_box.shape == (height, width, 3)):\n",
    "                varroas.append(img_box)\n",
    "\n",
    "    return varroas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_second_class_images(images, annotations, width, height):\n",
    "    # Find all images without varroas\n",
    "    empty_anno_index = []\n",
    "    for i in range(len(annotations)):\n",
    "        if len(annotations[i]) == 0:\n",
    "            empty_anno_index.append(i)\n",
    "\n",
    "    # Store the first 5 images (change later)\n",
    "    empty_anno_index = empty_anno_index[:5]\n",
    "    empty_pics = [images[i] for i in empty_anno_index]\n",
    "    \n",
    "    no_varroas = []\n",
    "    \n",
    "    # Slide over images and append all windows to the second class data array\n",
    "    for image in empty_pics:\n",
    "        for window in sliding_window(image, 20, (height, width)):\n",
    "            no_varroa_img = window[2]\n",
    "            if (no_varroa_img.shape == (height, width, 3)):\n",
    "                no_varroas.append(no_varroa_img)\n",
    "\n",
    "    return no_varroas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train features and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_shape = (45, 45)\n",
    "varroas_pos = np.stack(get_varroa_images(train, train_annotations, window_shape[0], window_shape[1]), axis=0)\n",
    "varroas_neg = np.stack(create_second_class_images(train, train_annotations, window_shape[0], window_shape[1]), axis=0)\n",
    "train_features = np.vstack((varroas_pos, varroas_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41753, 45, 45, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pos = np.ones((varroas_pos.shape[0]))\n",
    "label_neg = np.zeros((varroas_neg.shape[0]))\n",
    "train_labels = np.concatenate((label_pos, label_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41753,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_float = train_features.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (train_features.shape[1], train_features.shape[2], train_features.shape[3])\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - shape:  (41753, 6075) (41753, 2)\n"
     ]
    }
   ],
   "source": [
    "def reformat(dataset, labels):\n",
    "    \"\"\"\n",
    "        Reformat the data to the one-hot and flattened mode\n",
    "    \"\"\"\n",
    "    # Get image sizes\n",
    "    sizes = dataset.shape\n",
    "    n_dataset = dataset.reshape((-1, image_size[0] * image_size[1] * image_size[2])).astype(np.float32)\n",
    "\n",
    "    # Convert to the one hot format\n",
    "    n_labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "    return n_dataset, n_labels\n",
    "\n",
    "\n",
    "num_labels = 2\n",
    "\n",
    "train_images, train_labels = reformat(train_features, train_labels)\n",
    "#test_images, test_labels = reformat(test_images, test_labels)\n",
    "\n",
    "# Display the files\n",
    "print(\"Training Set - shape: \", train_images.shape, train_labels.shape)\n",
    "#print(\"Test Set - shape: \", test_images.shape, test_labels.shape)\n",
    "#print(\"Test Set labels - [1 to 5]: \\n\", test_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "        Divides the number of true predictions to the number of total predictions\n",
    "    \"\"\"\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the number of nodes for the hidden layers\n",
    "hidden_nodes_1=4096\n",
    "hidden_nodes_2=2048\n",
    "hidden_nodes_3=1024\n",
    "hidden_nodes_4=512\n",
    "\n",
    "MLP_GRAPH = tf.Graph()\n",
    "\n",
    "with MLP_GRAPH.as_default():\n",
    "    \"\"\"\n",
    "        For the training data we use place holders in order to feed them\n",
    "        in the run time with those mini bitches :D\n",
    "    \"\"\"\n",
    "    TF_TRAIN_DATASET = tf.placeholder(tf.float32, shape=(None, image_size[0] * image_size[1] * image_size[2]))\n",
    "    TF_TRAIN_LABELS = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    TF_TRAIN_TEST_DATASET = tf.constant(train_images)\n",
    "\n",
    "    \"\"\"\n",
    "       The first hidden layer with 1024 nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"FirstHidden\"):\n",
    "        \"\"\"\n",
    "            Initialize the hidden weights and biases\n",
    "        \"\"\"\n",
    "        HIDDEN_WEIGHTS_1=tf.Variable(tf.random_normal(shape=[image_size[0] * image_size[1] * image_size[2], hidden_nodes_1], stddev=0.1))\n",
    "        HIDDEN_BIASES_1 =tf.Variable(tf.random_normal(shape=[hidden_nodes_1], stddev=0.1))\n",
    "\n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and then apply D(S(WX + b), L) on them for the hidden layer\n",
    "            The relu is applied on the hidden layer nodes only\n",
    "        \"\"\"\n",
    "        TRAIN_HIDDEN_LOGITS_1 = tf.nn.relu(tf.matmul(TF_TRAIN_DATASET, HIDDEN_WEIGHTS_1) + HIDDEN_BIASES_1)\n",
    "        TEST_HIDDEN_LOGITS_1 = tf.nn.relu(tf.matmul(TF_TRAIN_TEST_DATASET, HIDDEN_WEIGHTS_1) + HIDDEN_BIASES_1)\n",
    "        \n",
    "    \"\"\"\n",
    "       The second hidden layer with 512 nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"SecondHidden\"):\n",
    "        \n",
    "        #Add your code for implementation of the second layer here\n",
    "        \"\"\"\n",
    "            Initialize the weights and biases for the second hidden layer\n",
    "        \"\"\"\n",
    "        # We need to match the output of the previous hidden layer\n",
    "        HIDDEN_WEIGHTS_2=tf.Variable(tf.random_normal(shape=[hidden_nodes_1, hidden_nodes_2], stddev=0.1))\n",
    "        HIDDEN_BIASES_2 =tf.Variable(tf.random_normal(shape=[hidden_nodes_2], stddev=0.1))\n",
    "        \n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and then apply D(S(WX + b), L) on them for the hidden layer\n",
    "            The relu is applied on the hidden layer nodes only\n",
    "        \"\"\"\n",
    "        TRAIN_HIDDEN_LOGITS_2 = tf.nn.relu(tf.matmul(TRAIN_HIDDEN_LOGITS_1, HIDDEN_WEIGHTS_2) + HIDDEN_BIASES_2)\n",
    "        TEST_HIDDEN_LOGITS_2 = tf.nn.relu(tf.matmul(TEST_HIDDEN_LOGITS_1, HIDDEN_WEIGHTS_2) + HIDDEN_BIASES_2)\n",
    "    \n",
    "    with tf.name_scope(\"ThirdHidden\"):\n",
    "        \n",
    "        #Add your code for implementation of the second layer here\n",
    "        \"\"\"\n",
    "            Initialize the weights and biases for the second hidden layer\n",
    "        \"\"\"\n",
    "        # We need to match the output of the previous hidden layer\n",
    "        HIDDEN_WEIGHTS_3=tf.Variable(tf.random_normal(shape=[hidden_nodes_2, hidden_nodes_3], stddev=0.1))\n",
    "        HIDDEN_BIASES_3 =tf.Variable(tf.random_normal(shape=[hidden_nodes_3], stddev=0.1))\n",
    "        \n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and then apply D(S(WX + b), L) on them for the hidden layer\n",
    "            The relu is applied on the hidden layer nodes only\n",
    "        \"\"\"\n",
    "        TRAIN_HIDDEN_LOGITS_3 = tf.nn.relu(tf.matmul(TRAIN_HIDDEN_LOGITS_2, HIDDEN_WEIGHTS_3) + HIDDEN_BIASES_3)\n",
    "        TEST_HIDDEN_LOGITS_3 = tf.nn.relu(tf.matmul(TEST_HIDDEN_LOGITS_2, HIDDEN_WEIGHTS_3) + HIDDEN_BIASES_3)\n",
    "    \n",
    "    with tf.name_scope(\"FourthHidden\"):\n",
    "        \n",
    "        #Add your code for implementation of the second layer here\n",
    "        \"\"\"\n",
    "            Initialize the weights and biases for the second hidden layer\n",
    "        \"\"\"\n",
    "        # We need to match the output of the previous hidden layer\n",
    "        HIDDEN_WEIGHTS_4=tf.Variable(tf.random_normal(shape=[hidden_nodes_3, hidden_nodes_4], stddev=0.1))\n",
    "        HIDDEN_BIASES_4 =tf.Variable(tf.random_normal(shape=[hidden_nodes_4], stddev=0.1))\n",
    "        \n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and then apply D(S(WX + b), L) on them for the hidden layer\n",
    "            The relu is applied on the hidden layer nodes only\n",
    "        \"\"\"\n",
    "        TRAIN_HIDDEN_LOGITS_4 = tf.nn.relu(tf.matmul(TRAIN_HIDDEN_LOGITS_3, HIDDEN_WEIGHTS_4) + HIDDEN_BIASES_4)\n",
    "        TEST_HIDDEN_LOGITS_4 = tf.nn.relu(tf.matmul(TEST_HIDDEN_LOGITS_3, HIDDEN_WEIGHTS_4) + HIDDEN_BIASES_4)\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"Softmax-Linear\"):\n",
    "        \"\"\"\n",
    "            Initialize the main weights and biases\n",
    "        \"\"\"\n",
    "        WEIGHTS=tf.Variable(tf.random_normal(shape=[hidden_nodes_4, num_labels], stddev=0.1))\n",
    "        BIASES=tf.Variable(tf.random_normal(shape=[num_labels], stddev=0.1))\n",
    "\n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and the apply D(S(WX + b), L) on them for the final layer\n",
    "        \"\"\"\n",
    "        TRAIN_LOGITS = tf.matmul(TRAIN_HIDDEN_LOGITS_4, WEIGHTS) + BIASES\n",
    "        TEST_LOGITS = tf.matmul(TEST_HIDDEN_LOGITS_4, WEIGHTS) + BIASES\n",
    "\n",
    "        LOSS = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=TRAIN_LOGITS, labels=TF_TRAIN_LABELS))\n",
    "\n",
    "        OPTIMIZER = tf.train.GradientDescentOptimizer(0.0005).minimize(LOSS)\n",
    "        tf.add_to_collection(\"activation\", TRAIN_LOGITS)\n",
    "\n",
    "        TRAIN_PREDICTION = tf.nn.softmax(TRAIN_LOGITS)\n",
    "        TEST_PREDICTION = tf.nn.softmax(TEST_LOGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_MLP(num_iterations, num_samples):\n",
    "    \n",
    "    with tf.Session(graph=MLP_GRAPH) as session:\n",
    "\n",
    "        \"\"\"\n",
    "            Start the above variable initialization\n",
    "        \"\"\"\n",
    "        #tf.initialize_all_variables().run()\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Variables initialized\")\n",
    "\n",
    "        for step in range(num_iterations):\n",
    "            \"\"\"\n",
    "                Select the desired samples\n",
    "            \"\"\"\n",
    "            TRAIN_DATASET_S = train_images[:num_samples]\n",
    "            TRAIN_LABELS_S = train_labels[:num_samples]\n",
    "            \"\"\"\n",
    "                Generate a random base and then generate a minibatch\n",
    "            \"\"\"\n",
    "            \n",
    "            indices = np.random.choice(range(TRAIN_LABELS_S.shape[0]\n",
    "                                             ), batch_size)\n",
    "\n",
    "            BATCH_DATA = TRAIN_DATASET_S[indices, :]\n",
    "            BATCH_LABELS = TRAIN_LABELS_S[indices, :]\n",
    "\n",
    "            \"\"\"\n",
    "                Feed the current session with batch data\n",
    "            \"\"\"\n",
    "            FEED_DICT = {TF_TRAIN_DATASET: BATCH_DATA, TF_TRAIN_LABELS: BATCH_LABELS}\n",
    "            _, l, predictions = session.run([OPTIMIZER, LOSS, TRAIN_PREDICTION], feed_dict=FEED_DICT)\n",
    "\n",
    "            #if (step == num_iterations - 1):\n",
    "            #    acc=accuracy(TEST_PREDICTION.eval(), test_labels)\n",
    "            #    print(\"Test accuracy: \", accuracy(TEST_PREDICTION.eval(), test_labels))\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Step: {}\".format(step))\n",
    "            \n",
    "            if (step == num_iterations - 1):\n",
    "                acc=accuracy(TEST_PREDICTION.eval(), train_labels)\n",
    "                print(\"Train accuracy: \", accuracy(TEST_PREDICTION.eval(), train_labels))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5000 training samples to test the MLP model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 500\n",
      "Step: 1000\n",
      "Step: 1500\n",
      "Train accuracy:  17.577180082868296\n",
      "The total runtime for the test was 462.56\n",
      "\n",
      "Using 10000 training samples to test the MLP model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 500\n",
      "Step: 1000\n",
      "Step: 1500\n",
      "Train accuracy:  82.4228199171317\n",
      "The total runtime for the test was 479.07\n",
      "\n",
      "Using 25000 training samples to test the MLP model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 500\n",
      "Step: 1000\n",
      "Step: 1500\n",
      "Train accuracy:  82.4228199171317\n",
      "The total runtime for the test was 491.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZES = [5000, 10000, 25000]\n",
    "\n",
    "# Import time to see how long the execution takes\n",
    "import time\n",
    "\n",
    "for ts in TRAINING_SIZES:\n",
    "    print(\"Using {0} training samples to test the MLP model\".format(ts))\n",
    "    start = time.time()\n",
    "    optimize_MLP(2000, ts)\n",
    "    end = time.time()\n",
    "    print(\"The total runtime for the test was {0:0.2f}\\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined a CNN with 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ada/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "conv_kernel = 5\n",
    "output1 = 16\n",
    "output2 = 32\n",
    "output3 = 64\n",
    "STRIDE_CONV = [1, 1, 1, 1]\n",
    "POOL_KERNEL = [1, 2, 2, 1]\n",
    "POOL_STRIDE = [1, 2, 2, 1]\n",
    "\n",
    "CNN_GRAPH = tf.Graph()\n",
    "\n",
    "with CNN_GRAPH.as_default():\n",
    "    \"\"\"\n",
    "        For the training data we use place holders in order to feed them\n",
    "        in the run time with those mini batches :D\n",
    "    \"\"\"\n",
    "    TF_TRAIN_DATASET = tf.placeholder(tf.float32, shape=(None, image_size[0], image_size[1], image_size[2]))\n",
    "    TF_TRAIN_LABELS = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    TF_TRAIN_TEST_DATASET = tf.constant(train_features_float)\n",
    "\n",
    "    \"\"\"\n",
    "       The first convolutional layer with kernel=5x5, output after max_pool is (?, 20, 20, 16)\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Conv1\"):\n",
    "        # [kernel, kernel, channels, output_shape]\n",
    "        HIDDEN_WEIGHTS_1=tf.Variable(\n",
    "            tf.random_normal(shape=[conv_kernel, conv_kernel, 3, output1], stddev=0.1)\n",
    "        )\n",
    "        HIDDEN_BIASES_1 =tf.Variable(tf.random_normal(shape=[output1], stddev=0.1))\n",
    "        \n",
    "        TRAIN_CONV_1 = tf.nn.conv2d(TF_TRAIN_DATASET, HIDDEN_WEIGHTS_1, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_1\n",
    "        TEST_CONV_1 = tf.nn.conv2d(TF_TRAIN_TEST_DATASET, HIDDEN_WEIGHTS_1, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_1\n",
    "        TRAIN_POOL_LOGITS_1 = tf.nn.relu(tf.nn.max_pool(TRAIN_CONV_1, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        TEST_POOL_LOGITS_1 = tf.nn.relu(tf.nn.max_pool(TEST_CONV_1, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        #print(TRAIN_CONV_1.shape)\n",
    "        #print(TRAIN_POOL_LOGITS_1.shape)\n",
    "\n",
    "    \"\"\"\n",
    "       The second convolutional layer with kernel=5x5, output after max_pool is (?, 8, 8, 32)\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Conv2\"):\n",
    "        # Match weights to the output of the previous layer\n",
    "        HIDDEN_WEIGHTS_2=tf.Variable(\n",
    "            tf.random_normal(shape=[conv_kernel, conv_kernel, output1, output2], stddev=0.1)\n",
    "        )\n",
    "        HIDDEN_BIASES_2 =tf.Variable(tf.random_normal(shape=[output2], stddev=0.1))\n",
    "\n",
    "        \n",
    "        TRAIN_CONV_2 = tf.nn.conv2d(TRAIN_POOL_LOGITS_1, HIDDEN_WEIGHTS_2, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_2\n",
    "        TEST_CONV_2 = tf.nn.conv2d(TEST_POOL_LOGITS_1, HIDDEN_WEIGHTS_2, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_2\n",
    "        TRAIN_POOL_LOGITS_2 = tf.nn.relu(tf.nn.max_pool(TRAIN_CONV_2, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        TEST_POOL_LOGITS_2 = tf.nn.relu(tf.nn.max_pool(TEST_CONV_2, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        #print(TRAIN_CONV_2.shape)\n",
    "        #print(TRAIN_POOL_LOGITS_2.shape)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "       The third convolutional layer with kernel=5x5, output after max_pool is (?, 2, 2, 64)\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Conv3\"):\n",
    "        # Match weights to the output of the previous layer\n",
    "        HIDDEN_WEIGHTS_3=tf.Variable(\n",
    "            tf.random_normal(shape=[conv_kernel, conv_kernel, output2, output3], stddev=0.1)\n",
    "        )\n",
    "        HIDDEN_BIASES_3 =tf.Variable(tf.random_normal(shape=[output3], stddev=0.1))\n",
    "\n",
    "        \n",
    "        TRAIN_CONV_3 = tf.nn.conv2d(TRAIN_POOL_LOGITS_2, HIDDEN_WEIGHTS_3, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_3\n",
    "        TEST_CONV_3 = tf.nn.conv2d(TEST_POOL_LOGITS_2, HIDDEN_WEIGHTS_3, strides=STRIDE_CONV, padding='VALID') + HIDDEN_BIASES_3\n",
    "        TRAIN_POOL_LOGITS_3 = tf.nn.relu(tf.nn.max_pool(TRAIN_CONV_3, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        TEST_POOL_LOGITS_3 = tf.nn.relu(tf.nn.max_pool(TEST_CONV_3, ksize=POOL_KERNEL, strides=POOL_STRIDE, padding='VALID'))\n",
    "        #print(TRAIN_CONV_3.shape)\n",
    "        #print(TRAIN_POOL_LOGITS_3.shape)\n",
    "    \n",
    "    with tf.name_scope(\"Flatten\"):\n",
    "        # Flatten before applying linear layer for output\n",
    "        sizes = TRAIN_POOL_LOGITS_3.shape\n",
    "        TRAIN_FLATTEN = tf.reshape(TRAIN_POOL_LOGITS_3, [-1, sizes[1] * sizes[2] * sizes[3]])\n",
    "        TEST_FLATTEN = tf.reshape(TEST_POOL_LOGITS_3, [-1, sizes[1] * sizes[2] * sizes[3]])\n",
    "        \n",
    "        #print(TRAIN_FLATTEN.shape)\n",
    "\n",
    "    with tf.name_scope(\"Softmax-Linear\"):\n",
    "        \"\"\"\n",
    "            Initialize the output weights and biases\n",
    "        \"\"\"\n",
    "        WEIGHTS=tf.Variable(tf.random_normal(shape=[256, num_labels], stddev=0.1))\n",
    "        BIASES=tf.Variable(tf.random_normal(shape=[num_labels], stddev=0.1))\n",
    "\n",
    "        \"\"\"\n",
    "            Compute the logits WX + b and the apply D(S(WX + b), L) on them for the final layer\n",
    "        \"\"\"\n",
    "        TRAIN_LOGITS = tf.matmul(TRAIN_FLATTEN, WEIGHTS) + BIASES\n",
    "        TEST_LOGITS = tf.matmul(TEST_FLATTEN, WEIGHTS) + BIASES\n",
    "\n",
    "        LOSS = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=TRAIN_LOGITS, labels=TF_TRAIN_LABELS))\n",
    "\n",
    "        OPTIMIZER = tf.train.GradientDescentOptimizer(0.0005).minimize(LOSS)\n",
    "        tf.add_to_collection(\"activation\", TRAIN_LOGITS)\n",
    "\n",
    "        TRAIN_PREDICTION = tf.nn.softmax(TRAIN_LOGITS)\n",
    "        TEST_PREDICTION = tf.nn.softmax(TEST_LOGITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_CNN(num_iterations, num_samples):\n",
    "    \n",
    "    with tf.Session(graph=CNN_GRAPH) as session:\n",
    "\n",
    "        \"\"\"\n",
    "            Start the above variable initialization\n",
    "        \"\"\"\n",
    "        #tf.initialize_all_variables().run()\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Variables initialized\")\n",
    "\n",
    "        for step in range(num_iterations):\n",
    "            \"\"\"\n",
    "                Select the desired samples\n",
    "            \"\"\"\n",
    "            TRAIN_DATASET_S = train_features_float[:num_samples]\n",
    "            TRAIN_LABELS_S = train_labels[:num_samples]\n",
    "            \"\"\"\n",
    "                Generate a random base and then generate a minibatch\n",
    "            \"\"\"\n",
    "            \n",
    "            indices = np.random.choice(range(TRAIN_LABELS_S.shape[0]\n",
    "                                             ), batch_size)\n",
    "\n",
    "            BATCH_DATA = TRAIN_DATASET_S[indices, :]\n",
    "            BATCH_LABELS = TRAIN_LABELS_S[indices, :]\n",
    "\n",
    "            \"\"\"\n",
    "                Feed the current session with batch data\n",
    "            \"\"\"\n",
    "            FEED_DICT = {TF_TRAIN_DATASET: BATCH_DATA, TF_TRAIN_LABELS: BATCH_LABELS}\n",
    "            _, l, predictions = session.run([OPTIMIZER, LOSS, TRAIN_PREDICTION], feed_dict=FEED_DICT)\n",
    "\n",
    "            #if (step == num_iterations - 1):\n",
    "            #    acc=accuracy(TEST_PREDICTION.eval(), test_labels)\n",
    "            #    print(\"Test accuracy: \", accuracy(TEST_PREDICTION.eval(), test_labels))\n",
    "            if (step % 10 == 0):\n",
    "                print(\"Step: {}\".format(step))\n",
    "            \n",
    "            if (step == num_iterations - 1):\n",
    "                acc=accuracy(TEST_PREDICTION.eval(), train_labels)\n",
    "                print(\"Train accuracy: \", accuracy(TEST_PREDICTION.eval(), train_labels))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5000 training samples to test the CNN model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 10\n",
      "Step: 20\n",
      "Step: 30\n",
      "Step: 40\n",
      "Step: 50\n",
      "Step: 60\n",
      "Step: 70\n",
      "Step: 80\n",
      "Step: 90\n",
      "Train accuracy:  17.577180082868296\n",
      "The total runtime for the test was 275.12\n",
      "\n",
      "Using 10000 training samples to test the CNN model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 10\n",
      "Step: 20\n",
      "Step: 30\n",
      "Step: 40\n",
      "Step: 50\n",
      "Step: 60\n",
      "Step: 70\n",
      "Step: 80\n",
      "Step: 90\n",
      "Train accuracy:  82.4228199171317\n",
      "The total runtime for the test was 187.98\n",
      "\n",
      "Using 25000 training samples to test the CNN model\n",
      "Variables initialized\n",
      "Step: 0\n",
      "Step: 10\n",
      "Step: 20\n",
      "Step: 30\n",
      "Step: 40\n",
      "Step: 50\n",
      "Step: 60\n",
      "Step: 70\n",
      "Step: 80\n",
      "Step: 90\n",
      "Train accuracy:  82.4228199171317\n",
      "The total runtime for the test was 261.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZES = [5000, 10000, 25000]\n",
    "\n",
    "#Add your code here\n",
    "\n",
    "# Import time to see how long the execution takes\n",
    "import time\n",
    "\n",
    "for ts in TRAINING_SIZES:\n",
    "    print(\"Using {0} training samples to test the CNN model\".format(ts))\n",
    "    start = time.time()\n",
    "    optimize_CNN(100, ts)\n",
    "    end = time.time()\n",
    "    print(\"The total runtime for the test was {0:0.2f}\\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "    size = img.shape\n",
    "    if len(size) == 3:\n",
    "        ax.imshow(img)\n",
    "        ax.set_title('({} px, {} px, depth {})'.format(size[0], size[1], size[2]))\n",
    "    else:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title('({} px, {} px), single channel'.format(size[0], size[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_annotation(img_nb, annotations, img = None):\n",
    "    if annotations == [] : \n",
    "        print(\"No varroa here!\")\n",
    "        return None\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    for anno in annotations:\n",
    "        rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                  anno['bbox'][1]), \n",
    "                                  anno['bbox'][2],\n",
    "                                  anno['bbox'][3],\n",
    "            linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    if img is not None: # img from argument\n",
    "        size = img.shape\n",
    "        if len(size) == 3:\n",
    "            ax.imshow(img)\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px, depth {})'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1], size[2]))\n",
    "        else:\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px), single channel'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1]))\n",
    "    else: # image from collection\n",
    "        size = img_collection[img_nb].shape\n",
    "        if len(size) == 3:\n",
    "            ax.imshow(img_collection[img_nb])\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px, depth {})'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1], size[2]))\n",
    "        else:\n",
    "            ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px), single channel'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(img, th_low = 0, th_high = np.Inf):\n",
    "    # Find contours\n",
    "    contours,l = find_contours(img)\n",
    "    plt.subplots(1,1,figsize=(6,6))\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    contours,l = contour_threshold_length(contours, th_low, th_high)\n",
    "    \n",
    "    for contour in contours:\n",
    "        plt.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "    \n",
    "    plt.title(\"{} contours between threholds {} and {}\".format(l,\n",
    "                                                              th_low,\n",
    "                                                              th_high))\n",
    "    plt.show()\n",
    "\n",
    "def plot_contours_histogram(img):\n",
    "    _, lengths = find_contours(img)\n",
    "    plt.subplots(1,1,figsize=(10,6))\n",
    "    plt.hist(lengths, bins='auto')\n",
    "    plt.title(\"Histogram with 'auto' bins\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxlist_and_annotations(img_nb, boxlist, annotations) :\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    \n",
    "    # plot boxes\n",
    "    tmp_im = np.zeros(img_collection[img_nb].shape)\n",
    "    for box in boxlist:\n",
    "        #print(box)\n",
    "        for x in range(box[0], box[2] + box[0]) :\n",
    "            for y in range(box[1], box[3] + box[1]):\n",
    "                tmp_im[y,x] = 1.0\n",
    "    ax.imshow(tmp_im, cmap = 'gray')\n",
    "    \n",
    "    # plot annotations\n",
    "    if annotations != [] : \n",
    "        for anno in annotations:\n",
    "            rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                      anno['bbox'][1]), \n",
    "                                      anno['bbox'][2],\n",
    "                                      anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        no_varroa = len(annotations)\n",
    "    else:\n",
    "        no_varroa = 0\n",
    "\n",
    "    #ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "    ax.set_title('img nb {}, no varroae {}, no boxes {}'.format(\n",
    "        img_nb,no_varroa, len(boxlist)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours_and_annotations(img_nb, contours, annotations) :\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    \n",
    "    # plot contours\n",
    "    for contour in contours:\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "    \n",
    "    # plot annotations\n",
    "    if annotations != [] :\n",
    "        for anno in annotations:\n",
    "            rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                      anno['bbox'][1]), \n",
    "                                      anno['bbox'][2],\n",
    "                                      anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        no_varroa = len(annotations)\n",
    "    else:\n",
    "        no_varroa = 0\n",
    "\n",
    "    #ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "    ax.set_title('img nb {}, no varroae {}, no contours {}'.format(\n",
    "        img_nb,no_varroa, len(contours)))\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
