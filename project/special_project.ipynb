{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import scipy.io\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.morphology as mp\n",
    "from skimage import measure\n",
    "\n",
    "#import sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = os.path.join(os.pardir, 'data') # works for Herman\n",
    "#data_base_path = ('data')\n",
    "data_folder = 'project-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "\n",
    "    train_dir = os.path.join(data_base_path, data_folder +'/images/train/')\n",
    "    dir_train_list = sorted(os.listdir(train_dir))\n",
    "    train = [skimage.io.imread(os.path.join(train_dir, file)) for file in dir_train_list]\n",
    "\n",
    "    \n",
    "    test_dir = os.path.join(data_base_path, data_folder +'/images/test/')\n",
    "    dir_test_list = sorted(os.listdir(test_dir))\n",
    "    test = [skimage.io.imread(os.path.join(test_dir, file)) for file in dir_test_list]\n",
    "    \n",
    "    val_dir = os.path.join(data_base_path, data_folder +'/images/validation/')\n",
    "    dir_val_list = sorted(os.listdir(val_dir))\n",
    "    validation = [skimage.io.imread(os.path.join(val_dir, file)) for file in dir_val_list]\n",
    "    \n",
    "    return train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations():\n",
    "    dir_train = os.path.join(data_base_path, data_folder + '/annotations/train/')\n",
    "    dir_train_list = sorted(os.listdir(dir_train))\n",
    "    train_files = [f for f in dir_train_list if os.path.isfile(os.path.join(dir_train, f))]\n",
    "    train_annotations = [parse_xml_file(os.path.join(dir_train, file)) for file in train_files]\n",
    "    \n",
    "    \n",
    "    dir_test = os.path.join(data_base_path, data_folder + '/annotations/test/')\n",
    "    dir_test_list = sorted(os.listdir(dir_test))\n",
    "    test_files = [f for f in dir_test_list if os.path.isfile(os.path.join(dir_test, f))]\n",
    "    test_annotations = [parse_xml_file(os.path.join(dir_test, file)) for file in test_files]\n",
    "    \n",
    "    dir_val = os.path.join(data_base_path, data_folder + '/annotations/validation/')\n",
    "    dir_val_list = sorted(os.listdir(dir_val))\n",
    "    val_files = [f for f in dir_val_list if os.path.isfile(os.path.join(dir_val, f))]\n",
    "    validation_annotations = [parse_xml_file(os.path.join(dir_val, file)) for file in val_files]\n",
    "    \n",
    "    return train_annotations, test_annotations, validation_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations, test_annotations, validation_annotations = load_annotations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_yellow(img):\n",
    "    out = img.copy()\n",
    "    \n",
    "    red = out[:,:,0]\n",
    "    green = out[:,:,1]\n",
    "    blue = out[:,:,2]\n",
    "    \n",
    "    is_yellow =  (red > 100) & (red < 250) & (green > 100) & (green < 250) & (blue > 0) & (blue < 200)\n",
    "    \n",
    "    red[is_yellow] = 255\n",
    "    green[is_yellow] = 255\n",
    "    blue[is_yellow] = 255\n",
    "    \n",
    "    out[:,:,0] = red\n",
    "    out[:,:,1] = green\n",
    "    out[:,:,2] = blue\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholding the image between two thresholds\n",
    "def threshold(image, th1, th2):\n",
    "    th_img = image.copy()\n",
    "    th_img[th_img<th1] = 0\n",
    "    th_img[th_img>th2] = 0\n",
    "    th_img[(th_img>=th1) & (th_img<=th2)] = 255\n",
    "    return th_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(img, nb):\n",
    "    for i in range(nb):\n",
    "        img = mp.erosion(mp.erosion(skimage.img_as_ubyte(img)))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef preprocess_image(img):\\n    img = remove_yellow(img)\\n    img_g = rgb2gray(img)\\n    img_th = mp.erosion(mp.erosion(threshold(skimage.img_as_ubyte(img_g), 1, 100)))\\n    return img_th\\n    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    img = remove_yellow(img)\n",
    "    img_g = rgb2gray(img)\n",
    "    img_th = threshold(skimage.img_as_ubyte(img_g), 1, 100)\n",
    "    img_er = erode(img_th,1)\n",
    "    return img_er\n",
    "\n",
    "\"\"\"\n",
    "def preprocess_image(img):\n",
    "    img = remove_yellow(img)\n",
    "    img_g = rgb2gray(img)\n",
    "    img_th = mp.erosion(mp.erosion(threshold(skimage.img_as_ubyte(img_g), 1, 100)))\n",
    "    return img_th\n",
    "    \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(train, test, validation):\n",
    "    for i in range(len(train)):\n",
    "        train[i] = preprocess_image(train[i])\n",
    "        \n",
    "    for i in range(len(test)):\n",
    "        test[i] = preprocess_image(test[i])\n",
    "        \n",
    "    for i in range(len(validation)):\n",
    "        validation[i] = preprocess_image(validation[i])\n",
    "         \n",
    "    return train, test, validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "train_pro, test_pro, validation_pro = preprocess_images(train, test, validation[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb train images     : 800\n",
      "Nb test images      : 50\n",
      "Nb validation images: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Nb train images     : {}\".format(len(train_pro)))\n",
    "print(\"Nb test images      : {}\".format(len(test_pro)))\n",
    "print(\"Nb validation images: {}\".format(len(validation_pro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_method(method, nb_test_images = None, printVals = False):\n",
    "    def precision(tp, fp): return tp / (tp + fp)\n",
    "\n",
    "    def recall(tp, fn): return tp / (tp + fn)\n",
    "\n",
    "    def f1_score(tp, fp, fn):\n",
    "        if (tp == 0): return 0\n",
    "        return 2 * precision(tp, fp) * recall(tp, fn) / (precision(tp, fp) + recall(tp, fn))\n",
    "\n",
    "    def iou_bbox(predict, true):\n",
    "        \"\"\"\n",
    "        Calculate the IoU for two bounding boxes.\n",
    "        Based on:\n",
    "        https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation\n",
    "        \"\"\"\n",
    "\n",
    "        # Determine the coordinates of the intersection rectangle\n",
    "        x_left   = max(predict[0], true[0])\n",
    "        y_bottom = max(predict[1], true[1])\n",
    "        x_right  = min(predict[0] + predict[2], true[0] + true[2])\n",
    "        y_top    = min(predict[1] + predict[3], true[1] + true[3])\n",
    "\n",
    "        # If they do not overlap, return 0\n",
    "        if x_right < x_left or y_bottom > y_top:\n",
    "            return 0.0\n",
    "\n",
    "        intersection_area = (x_right - x_left) * (y_top - y_bottom)\n",
    "\n",
    "        # Compute area for both bounding boxes\n",
    "        bb1_area = predict[2] * predict[3]\n",
    "        bb2_area = true[2] * true[3]\n",
    "\n",
    "        # Compute the intersection over union by taking the intersection\n",
    "        # area and dividing it by the sum of prediction + ground-truth\n",
    "        # areas - the intersection area\n",
    "        iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "\n",
    "        return iou\n",
    "    \n",
    "    def update_progress(progress):\n",
    "        bar_length = 30\n",
    "        if isinstance(progress, int):\n",
    "            progress = float(progress)\n",
    "        if not isinstance(progress, float):\n",
    "            progress = 0\n",
    "        if progress < 0:\n",
    "            progress = 0\n",
    "        if progress >= 1:\n",
    "            progress = 1\n",
    "            \n",
    "        block = int(round(bar_length * progress))\n",
    "        clear_output(wait = True)\n",
    "        text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "        print(text)\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    # setup progress bar\n",
    "    limit = len(test_pro[:nb_test_images] if nb_test_images != None else test_pro)\n",
    "\n",
    "    for i in range(limit):\n",
    "        update_progress(i/limit)\n",
    "        # predict varroas\n",
    "        varroas_pred = method(test_pro[i])\n",
    "\n",
    "        # get true bounding boxes\n",
    "        varroas_true = []\n",
    "        for bbox in test_annotations[i]:\n",
    "               varroas_true.append(bbox['bbox'])\n",
    "\n",
    "        # get true and false positives\n",
    "        positives = []\n",
    "\n",
    "        for pb in varroas_pred:\n",
    "            true_pos = False\n",
    "\n",
    "            for tb in varroas_true:\n",
    "                if(iou_bbox(pb, tb) > 0.3):\n",
    "                    true_pos = True\n",
    "                    break;\n",
    "            positives.append(true_pos)\n",
    "\n",
    "        tp += positives.count(True)\n",
    "        fp += positives.count(False)\n",
    "\n",
    "        # get the false negatives\n",
    "        negatives = []\n",
    "\n",
    "        for tb in varroas_true:\n",
    "            fn = False\n",
    "\n",
    "            for pb in varroas_pred:\n",
    "                if(iou_bbox(pb, tb) > 0.3):\n",
    "                    fn = True\n",
    "                    break;\n",
    "            negatives.append(fn)\n",
    "\n",
    "        # Count all times no intersection was found\n",
    "        fn += negatives.count(False)\n",
    "    update_progress(1)\n",
    "    \n",
    "    if printVals :\n",
    "        print('The values for the given test images')\n",
    "        print(tp)\n",
    "        print(fn)\n",
    "        print(fp)\n",
    "\n",
    "    \n",
    "    print(\"\\n----------- SCORES -----------\")\n",
    "    print(\"Precision: {}\".format(precision(tp,fp)))\n",
    "    print(\"Recall   : {}\".format(recall(tp,fn)))\n",
    "    print(\"F1-score : {}\".format(f1_score(tp,fp,fn)))\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(img):\n",
    "    contours = measure.find_contours(img, 0)\n",
    "    lengths = []\n",
    "    for cnt in contours:\n",
    "        lengths.append(len(cnt))\n",
    "    return contours, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_threshold_length(contours, th_low = 0, th_high = np.Inf) :\n",
    "    # filters list of contours, keeps those within threshold limits\n",
    "    out = []\n",
    "    for n, contour in enumerate(contours):\n",
    "        if len(contour) > th_low and len(contour) < th_high :\n",
    "            out.append(contour)\n",
    "    return out, len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours2boxlist(contours):\n",
    "    boxes = []\n",
    "    for contour in contours :\n",
    "        x_min = int(np.min(contour[:,1]))\n",
    "        x_max = int(np.max(contour[:,1]))\n",
    "        y_min = int(np.min(contour[:,0]))\n",
    "        y_max = int(np.max(contour[:,0]))\n",
    "        \n",
    "        boxes.append([x_min, y_min, x_max - x_min, y_max - y_min])\n",
    "    \n",
    "    return boxes # [[x_1, y_1, w_1, h_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    #img = preprocess_image(img)\n",
    "    contours,_ = find_contours(img)\n",
    "    contours,_ = contour_threshold_length(contours,40,80)\n",
    "    boxlist = contours2boxlist(contours)\n",
    "    \n",
    "    return boxlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##############################] 100.0%\n",
      "\n",
      "----------- SCORES -----------\n",
      "Precision: 0.04203670811130847\n",
      "Recall   : 0.9861111111111112\n",
      "F1-score : 0.08063600227143669\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Your code\n",
    "validate_method(detect_by_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create our training features for the classifier. This is done by first finding the contours for all training annotations and then using them to compute the first 10 fourier descriptors of all contours. These will be our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(images, annotations):\n",
    "    '''\n",
    "    Input: Training images and training annotations\n",
    "    Output: Max length of the contours and an array with the contours of all training varroas\n",
    "    '''\n",
    "    max_len = 0\n",
    "    all_contours = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        for anno in annotations[i]:\n",
    "            bbox = anno['bbox']\n",
    "            img_box = images[i][bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]].copy()\n",
    "            im_bw = img_box\n",
    "\n",
    "            # Find contours using opencv\n",
    "            _, contours, _ = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            # Reshape to easily get x and y\n",
    "            if (len(contours) != 0):\n",
    "                contours_np = contours[0][:, 0, :]\n",
    "                all_contours.append(contours_np)\n",
    "\n",
    "                if (max_len < contours_np.shape[0]):\n",
    "                    max_len = contours_np.shape[0]\n",
    "\n",
    "    return max_len, np.array(all_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_descriptor(contours, length):\n",
    "    '''\n",
    "    Input: one contour, max lenght of all contours\n",
    "    Output: The 10 first fourrier descriptors of the contour\n",
    "    '''\n",
    "    \n",
    "    # Pad contour to max contour length\n",
    "    for i in range(length - len(contours)):\n",
    "        contours = np.concatenate([contours, np.array([[0, 0]])])\n",
    "    \n",
    "    # Create imag nums and descriptors\n",
    "    u_k = contours[:, 0] + 1j*contours[:, 1]\n",
    "    \n",
    "    fr = np.fft.fft(u_k)\n",
    "    \n",
    "    # Only return the 2nd and 3rd\n",
    "    return [fr[1], fr[2], fr[3], fr[4], fr[5], fr[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and normalize training features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len, contours = get_contours(train_pro, train_annotations)\n",
    "features = np.abs([(fourier_descriptor(c, max(max_len, max_len_fake))) for c in contours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05565764e-13, -3.07972234e-14, -4.50542272e-14, -1.77909765e-14,\n",
       "        1.05394350e-13, -4.78249579e-14])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.c_[ features, np.zeros(features.shape[0]) ]  \n",
    "scaler = preprocessing.StandardScaler().fit(features[:, 0:6])\n",
    "features_s = scaler.transform(features[:, 0:6])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_one = svm.OneClassSVM(nu=0.9)\n",
    "clf_svm_one.fit(features_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not miss any varroas the sliding window will take quite small steps (6-8px). This means that one varroa might be found several times. A merge_box function is implemented to merge overlapping bounding boxes before returning them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(bboxes_in):\n",
    "    bboxes = bboxes_in.copy()\n",
    "    for i in range(len(bboxes)):\n",
    "        for j in range(i+1, len(bboxes)):\n",
    "            if(iou_bbox(bboxes[i], bboxes[j]) > 0.3):\n",
    "\n",
    "                # Determine the coordinates of the intersection rectangle\n",
    "                x_left = min(bboxes[i][0], bboxes[j][0])\n",
    "                y_top = min(bboxes[i][1], bboxes[j][1])\n",
    "                x_right = max(bboxes[i][0] + bboxes[i][2], bboxes[j][0] + bboxes[j][2])\n",
    "                y_bottom = max(bboxes[i][1] + bboxes[i][3], bboxes[j][1] + bboxes[j][3])\n",
    "                \n",
    "                bboxes[j] = [x_left, y_top, x_right - x_left, y_bottom - y_top]\n",
    "                del bboxes[i]\n",
    "                break\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(image):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    \n",
    "    window_shape = (45, 45)\n",
    "    padding = max(max_len, max_len_fake)\n",
    "    varroas = []\n",
    "    for window in sliding_window(image, 6, window_shape):\n",
    "        im_bw = window[2]\n",
    "\n",
    "        # Find contours using opencv\n",
    "        _, contours, _ = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        #print(len(contours))\n",
    "\n",
    "        # Reshape to easily get x and y\n",
    "        if (len(contours) > 0):\n",
    "            contours_np = contours[0][:, 0, :]\n",
    "            descriptor = np.abs(fourier_descriptor(contours_np, padding))\n",
    "            test_ = scaler.transform(np.array([descriptor[:]]))\n",
    "            prob = clf_svm_one.predict(test_.reshape(1, -1))\n",
    "            # print(prob)\n",
    "            if (prob > 0):\n",
    "                varroas.append([window[0], window[1], window_shape[0], window_shape[1]])\n",
    "\n",
    "    return merge_boxes(varroas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation of result by repporting the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_method(detect_by_method_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = sliding_window(train[2], 100, (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "(winW, winH) = (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9f4903142ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwinW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwinH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Window\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for (x, y, window) in sliding_window(train[2], 100, (winW, winH)):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:\n",
    "        continue\n",
    "\n",
    "    # THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "    # MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE\n",
    "    # WINDOW\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "    size = img.shape\n",
    "    if len(size) == 3:\n",
    "        ax.imshow(img)\n",
    "        ax.set_title('({} px, {} px, depth {})'.format(size[0], size[1], size[2]))\n",
    "    else:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title('({} px, {} px), single channel'.format(size[0], size[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_annotation(img_nb, annotations, img = None):\n",
    "    if annotations == [] : \n",
    "        print(\"No varroa here!\")\n",
    "        return None\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    for anno in annotations:\n",
    "        rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                  anno['bbox'][1]), \n",
    "                                  anno['bbox'][2],\n",
    "                                  anno['bbox'][3],\n",
    "            linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    if img is not None: # img from argument\n",
    "        size = img.shape\n",
    "        if len(size) == 3:\n",
    "            ax.imshow(img)\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px, depth {})'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1], size[2]))\n",
    "        else:\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px), single channel'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1]))\n",
    "    else: # image from collection\n",
    "        size = img_collection[img_nb].shape\n",
    "        if len(size) == 3:\n",
    "            ax.imshow(img_collection[img_nb])\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px, depth {})'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1], size[2]))\n",
    "        else:\n",
    "            ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "            ax.set_title('img nb {}, no varroae {}, ({} px, {} px), single channel'.format(\n",
    "                img_nb,len(annotations_xmls[img_nb]), size[0], size[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(img, th_low = 0, th_high = np.Inf):\n",
    "    # Find contours\n",
    "    contours,l = find_contours(img)\n",
    "    plt.subplots(1,1,figsize=(6,6))\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    contours,l = contour_threshold_length(contours, th_low, th_high)\n",
    "    \n",
    "    for contour in contours:\n",
    "        plt.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "    \n",
    "    plt.title(\"{} contours between threholds {} and {}\".format(l,\n",
    "                                                              th_low,\n",
    "                                                              th_high))\n",
    "    plt.show()\n",
    "\n",
    "def plot_contours_histogram(img):\n",
    "    _, lengths = find_contours(img)\n",
    "    plt.subplots(1,1,figsize=(10,6))\n",
    "    plt.hist(lengths, bins='auto')\n",
    "    plt.title(\"Histogram with 'auto' bins\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxlist_and_annotations(img_nb, boxlist, annotations) :\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    \n",
    "    # plot boxes\n",
    "    tmp_im = np.zeros(img_collection[img_nb].shape)\n",
    "    for box in boxlist:\n",
    "        #print(box)\n",
    "        for x in range(box[0], box[2] + box[0]) :\n",
    "            for y in range(box[1], box[3] + box[1]):\n",
    "                tmp_im[y,x] = 1.0\n",
    "    ax.imshow(tmp_im, cmap = 'gray')\n",
    "    \n",
    "    # plot annotations\n",
    "    if annotations != [] : \n",
    "        for anno in annotations:\n",
    "            rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                      anno['bbox'][1]), \n",
    "                                      anno['bbox'][2],\n",
    "                                      anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        no_varroa = len(annotations)\n",
    "    else:\n",
    "        no_varroa = 0\n",
    "\n",
    "    #ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "    ax.set_title('img nb {}, no varroae {}, no boxes {}'.format(\n",
    "        img_nb,no_varroa, len(boxlist)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours_and_annotations(img_nb, contours, annotations) :\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    \n",
    "    # plot contours\n",
    "    for contour in contours:\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "    \n",
    "    # plot annotations\n",
    "    if annotations != [] :\n",
    "        for anno in annotations:\n",
    "            rect = patches.Rectangle((anno['bbox'][0], \n",
    "                                      anno['bbox'][1]), \n",
    "                                      anno['bbox'][2],\n",
    "                                      anno['bbox'][3],\n",
    "                linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        no_varroa = len(annotations)\n",
    "    else:\n",
    "        no_varroa = 0\n",
    "\n",
    "    #ax.imshow(img_collection[img_nb], cmap='gray')\n",
    "    ax.set_title('img nb {}, no varroae {}, no contours {}'.format(\n",
    "        img_nb,no_varroa, len(contours)))\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
